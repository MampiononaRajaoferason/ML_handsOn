{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist\n",
    "This checklist can guide you through your Machine Learning projects. There are eight main steps:\n",
    "1. Frame the problem and look at the big picture.\n",
    "2. Get the data.\n",
    "3. Explore the data to gain insights.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.\n",
    "5. Explore many different models and short-list the best ones.\n",
    "6. Fine-tune your models and combine them into a great solution.\n",
    "7. Present your solution.\n",
    "8. Launch, monitor, and maintain your system.\n",
    "Obviously, you should feel free to adapt this checklist to your needs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the Problem and Look at the Big Picture\n",
    "1. Define the objective in business terms.\n",
    "2. How will your solution be used?\n",
    "3. What are the current solutions/workarounds (if any)?\n",
    "4. How should you frame this problem (supervised/unsupervised, online/offline, etc.)?\n",
    "5. How should performance be measured?\n",
    "6. Is the performance measure aligned with the business objective?\n",
    "7. What would be the minimum performance needed to reach the business objective?\n",
    "8. What are comparable problems? Can you reuse experience or tools?\n",
    "9. Is human expertise available?\n",
    "10. How would you solve the problem manually?\n",
    "11. List the assumptions you (or others) have made so far.\n",
    "12. Verify assumptions if possible.\n",
    "\n",
    "## Get the Data\n",
    "Note: automate as much as possible so you can easily get fresh data.\n",
    "1. List the data you need and how much you need.\n",
    "2. Find and document where you can get that data.\n",
    "3. Check how much space it will take.\n",
    "4. Check legal obligations, and get authorization if necessary.\n",
    "5. Get access authorizations.\n",
    "6. Create a workspace (with enough storage space).\n",
    "7. Get the data.\n",
    "8. Convert the data to a format you can easily manipulate (without changing the data itself).\n",
    "9. Ensure sensitive information is deleted or protected (e.g., anonymized).\n",
    "10. Check the size and type of data (time series, sample, geographical, etc.).\n",
    "11. Sample a test set, put it aside, and never look at it (no data snooping!).\n",
    "## Explore the Data\n",
    "Note: try to get insights from a field expert for these steps.\n",
    "1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary).\n",
    "2. Create a Jupyter notebook to keep a record of your data exploration.\n",
    "3. Study each attribute and its characteristics:\n",
    "Name\n",
    "Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
    "% of missing values\n",
    "Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "Possibly useful for the task?\n",
    "Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
    "4. For supervised learning tasks, identify the target attribute(s).\n",
    "5. Visualize the data.\n",
    "6. Study the correlations between attributes.\n",
    "7. Study how you would solve the problem manually.\n",
    "8. Identify the promising transformations you may want to apply.\n",
    "9. Identify extra data that would be useful (go back to “Get the Data”).\n",
    "10. Document what you have learned.\n",
    "\n",
    "## Prepare the Data\n",
    "Notes:\n",
    "Work on copies of the data (keep the original dataset intact).\n",
    "Write functions for all data transformations you apply, for five reasons:\n",
    "So you can easily prepare the data the next time you get a fresh dataset\n",
    "So you can apply these transformations in future projects\n",
    "To clean and prepare the test set\n",
    "To clean and prepare new data instances once your solution is live\n",
    "To make it easy to treat your preparation choices as hyperparameters\n",
    "1. Data cleaning:\n",
    "Fix or remove outliers (optional).\n",
    "Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns).\n",
    "2. Feature selection (optional):\n",
    "Drop the attributes that provide no useful information for the task.\n",
    "3. Feature engineering, where appropriate:\n",
    "Discretize continuous features.\n",
    "Decompose features (e.g., categorical, date/time, etc.).\n",
    "Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.).\n",
    "Aggregate features into promising new features.\n",
    "4. Feature scaling: standardize or normalize features.\n",
    "\n",
    "## Short-List Promising Models\n",
    "Notes:\n",
    "If the data is huge, you may want to sample smaller training sets so you can train many different\n",
    "models in a reasonable time (be aware that this penalizes complex models such as large neural nets\n",
    "or Random Forests).\n",
    "Once again, try to automate these steps as much as possible.\n",
    "1. Train many quick and dirty models from different categories (e.g., linear, naive Bayes, SVM,\n",
    "Random Forests, neural net, etc.) using standard parameters.\n",
    "2. Measure and compare their performance.\n",
    "For each model, use N-fold cross-validation and compute the mean and standard deviation\n",
    "of the performance measure on the N folds.\n",
    "3. Analyze the most significant variables for each algorithm.\n",
    "4. Analyze the types of errors the models make.\n",
    "What data would a human have used to avoid these errors?\n",
    "5. Have a quick round of feature selection and engineering.\n",
    "6. Have one or two more quick iterations of the five previous steps.\n",
    "7. Short-list the top three to five most promising models, preferring models that make different\n",
    "types of errors.Fine-Tune the System\n",
    "Notes:\n",
    "You will want to use as much data as possible for this step, especially as you move toward the end\n",
    "of fine-tuning.\n",
    "As always automate what you can.\n",
    "1. Fine-tune the hyperparameters using cross-validation.\n",
    "Treat your data transformation choices as hyperparameters, especially when you are not\n",
    "sure about them (e.g., should I replace missing values with zero or with the median value?\n",
    "Or just drop the rows?).\n",
    "Unless there are very few hyperparameter values to explore, prefer random search over\n",
    "grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g.,\n",
    "using Gaussian process priors, as described by Jasper Snoek, Hugo Larochelle, and Ryan\n",
    "Adams).1\n",
    "2. Try Ensemble methods. Combining your best models will often perform better than running them\n",
    "individually.\n",
    "3. Once you are confident about your final model, measure its performance on the test set to\n",
    "estimate the generalization error.\n",
    "WARNING\n",
    "Don’t tweak your model after measuring the generalization error: you would just start overfitting the test set.\n",
    "\n",
    "## Present Your Solution\n",
    "1. Document what you have done.\n",
    "2. Create a nice presentation.\n",
    "Make sure you highlight the big picture first.\n",
    "3. Explain why your solution achieves the business objective.\n",
    "4. Don’t forget to present interesting points you noticed along the way.\n",
    "Describe what worked and what did not.\n",
    "List your assumptions and your system’s limitations.\n",
    "5. Ensure your key findings are communicated through beautiful visualizations or easy-to-remember\n",
    "statements (e.g., “the median income is the number-one predictor of housing prices”).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "#common imports \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# \n",
    "np.random.seed(42)\n",
    "\n",
    "#plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "#where to save the figures\n",
    "PROJECT_ROOT_DIR = '.'\n",
    "CHAPTER_ID = 'end_to_end_practical'\n",
    "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR,'images',CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def load_housing_data(housing_path = HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 columns, 1 categorical and 9 quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20640 entries/instances in the dataset\n",
    "\n",
    "total_bedrooms only have 20433 entries, 207 districts are missing this info. WE should take care of it later on\n",
    "\n",
    "\n",
    "The count, mean, min, and max rows are self-explanatory. Note that the null values are ignored (so, for\n",
    "example, count of total_bedrooms is 20,433, not 20,640). The std row shows the standard deviation\n",
    "(which measures how dispersed the values are). The 25%, 50%, and 75% rows show the corresponding\n",
    "percentiles: a percentile indicates the value below which a given percentage of observations in a group\n",
    "of observations falls. For example, 25% of the districts have a housing_median_age lower than 18,\n",
    "while 50% are lower than 29 and 75% are lower than 37. These are often called the 25th percentile (or\n",
    "1st quartile), the median, and the 75th percentile (or 3rd quartile)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE \n",
    "it measures the standard deviation4 of the errors the\n",
    "system makes in its predictions\n",
    "\n",
    "i.e, rmse represents 1 $\\sigma$\n",
    "\n",
    "1 $\\sigma$ = 68% \n",
    "\n",
    "2 $\\sigma$ = 95%\n",
    "\n",
    "3 $\\sigma$ = 99.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1324bfbe45e84ddbb9af1da45d7c5492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots\n",
    "from ipywidgets import interact \n",
    "@interact \n",
    "\n",
    "def plot_housing_hist():\n",
    "    housing.hist(bins=50, figsize=(20,15))\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display plots when a cell is executed.Notice a few things in these histograms:\n",
    "\n",
    "    First, the median income attribute does not look like it is expressed in US dollars (USD). Afterchecking with the team that collected the data, you are told that the data has been scaled andcapped at 15 (actually 15.0001) for higher median incomes, and at 0.5 (actually 0.4999) forlower median incomes. Working with preprocessed attributes is common in Machine Learning,and it is not necessarily a problem, but you should try to understand how the data was computed.\n",
    "    The housing median age and the median house value were also capped. The latter may be aserious problem since it is your target attribute (your labels). Your Machine Learning algorithmsmay learn that prices never go beyond that limit. You need to check with your client team (theteam that will use your system’s output) to see if this is a problem or not. If they tell you that theyneed precise predictions even beyond $500,000, then you have mainly two options:\n",
    "\n",
    "    <ul> \n",
    "        <li> Collect proper labels for the districts whose labels were capped.</li>\n",
    "        \n",
    "        <li>Remove those districts from the training set (and also from the test set, since your systemshould not be evaluated poorly if it predicts values beyond $500,000).</li>\n",
    "    </ul>  \n",
    "        \n",
    "\n",
    "    These attributes have very different scales. We will discuss this later in this chapter when weexplore feature scaling\n",
    "    Finally, many histograms are tail heavy: they extend much farther to the right of the median thanto the left. This may make it a bit harder for some Machine Learning algorithms to detectpatterns. We will try transforming these attributes later on to have more bell-shapeddistributions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test set¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#similar to train_test_split(dataset, ...)\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data)*test_ratio)\n",
    "    test_indices=shuffled_indices[:test_set_size]\n",
    "    train_indices=shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices],data.iloc[test_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512  train + 4128  test\n"
     ]
    }
   ],
   "source": [
    "train_test, test_set = split_train_test(housing, 0.2)\n",
    "print(len(train_test),\" train +\",len(test_set), \" test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
